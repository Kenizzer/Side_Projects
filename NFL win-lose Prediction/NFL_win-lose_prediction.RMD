---
title: "NFL 2002-2021 Score Differential"
author: "Kenizzer"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('ggpubr')
library('emmeans')
library('plotly')
library('tidyverse')
library("MASS")
library("scales")
library("caret")
library("AppliedPredictiveModeling")
library("ranger")
library("e1071")
library("randomForest")
library("alluvial")
library("matrixStats")
theme_set(theme_pubr())
```

## Add in data and print summary

This data set was generated by Reddit user **gigantoir** <https://www.reddit.com/r/NFLstatheads/comments/q73yd0/nfl_scores_20172020/>
I added the 2021 data that was scrapped from <https://www.footballdb.com/games/index.html> 
and 2002-2016 data from Reddit user **yuxbni76** <https://www.reddit.com/user/yuxbni76>

```{r}
Scores <- read.csv("nfl_dataset_2002-2019week6.csv", header=TRUE, sep= ",")
Scores$Home_win <- factor(Scores$score_home > Scores$score_away, labels=c("Home_loss", "Home_win"))
summary(Scores)
```

## Team colors
Team colors were extracted from <https://teamcolorcodes.com>, I took the first primary color
for each team and created a list that will be for later use. For the Browns and Titans I took the
secondary color as it seemed more *appropriate*.

```{r}
Team_colors <- c("SF"="#AA0000",
                 "CHI"="#0B162A",
                 "CIN"="#FB4F14",
                 "BUF"="#00338D",
                 "DEN"="#FB4F14",
                 "CLE"="#FF3C00",
                 "TB"="#D50A0A",
                 "ARI"="#97233F",
                 "LAC"="#0080C6",
                 "KC"="#E31837",
                 "IND"="#002C5F",
                 "DAL"="#041E42",
                 "MIA"="#008E97",
                 "PHI"="#004C54",
                 "ATL"="#A71930",
                 "NYG"="#0B2265",
                 "JAX"="#006778",
                 "NYJ"="#125740",
                 "DET"="#0076B6",
                 "GB"="#203731",
                 "CAR"="#0085CA",
                 "NE"="#002244",
                 "LV"="#000000",
                 "LA"="#003594",
                 "BAL"="#241773",
                 "WAS"="#773141",
                 "NO"="#D3BC8D",
                 "SEA"="#002244",
                 "PIT"="#FFB612",
                 "HOU"="#03202F",
                 "TEN"="#4B92DB",
                 "MIN"="#4F2683")
```


## Machine learning
```{r}

# Function to plot confusion matrix using ggtile plot from a confussion matrix object
# By user: Enrique Perez Herrero 
# on https://stackoverflow.com/questions/46063234/how-to-produce-a-confusion-matrix-and-find-the-misclassification-rate-of-the-na%C3%AF
ggplotConfusionMatrix <- function(m){
  mytitle <- paste("Accuracy", percent_format()(m$overall[1]),
                   "Kappa", percent_format()(m$overall[2]))
  
  d <- as.data.frame.matrix(m$table)
  drn <- colnames(d)
  drr <- rownames(d)
  drs <- rowSums(d)
  d <- d %>% mutate_if(is.numeric, funs(./drs))
  d <- d %>% gather(x, value)
  Y <- cbind(as.data.frame(m$table), Proportion = d$value)
  Y$Reference <- fct_rev(Y$Reference) # Added this line to get a downward diagonal 
  p <-
    ggplot(data = Y, aes(x = Reference, y = Prediction, fill= Proportion)) +
    geom_tile( colour = "white") +
    scale_fill_gradient(low = "white", high = "#14A02E", na.value = "white", limits=c(0,1)) +
    ggtitle(mytitle) +
    theme(legend.position = "right", axis.text.x = element_text(angle = 60, hjust = 1)) +
    guides(fill = guide_colorbar(frame.colour = "black", ticks = FALSE))
  return(p)
}



MachineLearning_RF_ranger <- function(DF, GROUPING, TREES) {
  # 80:20 data split
  train_index <- as.data.frame(DF %>% sample_n(round(length(Scores$date) * 0.8)))
  train_index <- match(rownames(train_index), rownames(DF))
  train_x <- as.data.frame(DF[train_index, ])
  test_y <- as.data.frame(DF[-train_index, ])
  
  
  # Train set, 3705
  train_x$Date <- rownames(train_x)
  Training_meta.df <- train_x # this might fail here
  train_x <- subset(Training_meta.df, select = -c(Home_win, score_home, score_away))
  rownames(train_x) <- train_x$Sample
  train_x <- subset(train_x, select = -c(Date))
  Training_meta.df <- subset(Training_meta.df, select = c(Home_win, score_home, score_away))
  rownames(Training_meta.df) <- Training_meta.df$Date 
  
  
  # Test set, 926 samples
  test_y$Date <- rownames(test_y)
  Testing_meta.df <- test_y
  test_y <- subset(Testing_meta.df, select = -c(Home_win, score_home, score_away))
  rownames(test_y) <- test_y$Sample
  test_y <- subset(test_y, select = -c(Date))
  Testing_meta.df <- subset(Testing_meta.df, select = c(Home_win, score_home, score_away))
  rownames(Testing_meta.df) <- Testing_meta.df$Date 
  
  
  # Training model
  Training_grid <- expand.grid(.mtry = seq(10, length(train_x), round(length(train_x)*0.1)), .splitrule= "gini",
                               .min.node.size = c(1, 5, 10))
  train_control <- trainControl(method="cv", number=10)
  RF_CM <- list()
  RF_CM[["RF_model"]] <- train(x = train_x, y = Training_meta.df[[GROUPING]], method = "ranger", importance = "permutation",
                               tuneGrid = Training_grid, trControl = train_control, num.trees = TREES)
  RF_prediction_3 <- predict(RF_CM[["RF_model"]], test_y)
  RF_CM[["CMatrix"]] <- confusionMatrix(RF_prediction_3, as.factor(Testing_meta.df[[GROUPING]]), mode = "everything")
  RF_CM[["CMatrixPLOT"]] <- ggplotConfusionMatrix(RF_CM[["CMatrix"]])
  RF_CM[["VarImporance"]] <- varImp(RF_CM[["RF_model"]])
  return(RF_CM)
}



Home_win_pred <- MachineLearning_RF_ranger(Scores, "Home_win", 500)

```

```{r}

# It seems the model is really keying in on the number of running attempts
# My best guess is when teams are ahead they run the ball to kill the clock
# maybe this causes inflated run attempt totals
varImp(Home_win_pred$RF_model)

plot(Home_win_pred[["VarImporance"]])

Home_win_pred$CMatrixPLOT



ggplot(Scores, aes(x = Home_win, y = rushing_attempts_away, fill = Home_win)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitterdodge(jitter.width = 0.8))
ggplot(Scores, aes(x = Home_win, y = turnovers_away, fill = Home_win)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitterdodge(jitter.width = 0.8))
ggplot(Scores, aes(x = Home_win, y = rushing_attempts_home, fill = Home_win)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitterdodge(jitter.width = 0.8))




anova(lm(passing_yards_home ~ Home_win, data = Scores))

ggplot(Scores, aes(x = Home_win, y = passing_yards_home, fill = Home_win)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitterdodge(jitter.width = 0.8))
ggplot(Scores, aes(x = Home_win, y = rushing_yards_home, fill = Home_win)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitterdodge(jitter.width = 0.8))






# How often do you win if you rush for 100 yards
summary(Scores[Scores$rushing_yards_home > 100,]$Home_win) / sum(summary(Scores[Scores$rushing_yards_home > 100,]$Home_win)) * 100
# How often do you win if you rush for 150 yards
summary(Scores[Scores$rushing_yards_home > 150,]$Home_win) / sum(summary(Scores[Scores$rushing_yards_home > 150,]$Home_win)) * 100
# How often do you win if you rush for 200 yards
summary(Scores[Scores$rushing_yards_home > 200,]$Home_win) / sum(summary(Scores[Scores$rushing_yards_home > 200,]$Home_win)) * 100
# How often do you win if you rush for 250 yards
summary(Scores[Scores$rushing_yards_home > 250,]$Home_win) / sum(summary(Scores[Scores$rushing_yards_home > 250,]$Home_win)) * 100
# How often do you win if you rush for 300 yards
summary(Scores[Scores$rushing_yards_home > 300,]$Home_win) / sum(summary(Scores[Scores$rushing_yards_home > 300,]$Home_win)) * 100


ggplot(Scores, aes(x = rushing_yards_home , y = passing_yards_home)) + geom_smooth() + geom_point(aes(color = Home_win), alpha = 0.8)
ggplot(Scores, aes(x = rushing_yards_away , y = passing_yards_away)) + geom_smooth() + geom_point(aes(color = Home_win), alpha = 0.8)


```
